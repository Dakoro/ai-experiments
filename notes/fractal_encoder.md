# Rapport D√©taill√© : Encodeur Fractal pour l'Apprentissage Causal Curieux

## R√©sum√© Ex√©cutif

Ce notebook pr√©sente une impl√©mentation innovante d'un agent d'apprentissage causal curieux utilisant un encodeur fractal. L'architecture combine la d√©couverte automatique de m√©ta-√©tats avec l'apprentissage de graphes causaux, appliqu√©e au probl√®me classique de la porte verrouill√©e/d√©verrouill√©e.

## Architecture du Syst√®me

### 1. Encodeur Fractal (`FractalEncoder`)

L'encodeur fractal constitue le c≈ìur du syst√®me de repr√©sentation. Il utilise une architecture multi-niveaux avec des connexions r√©siduelles sophistiqu√©es :

- **Structure hi√©rarchique** : 3 niveaux de transformation par d√©faut
- **Normalisation par couche** : Stabilise l'entra√Ænement √† chaque niveau
- **M√©canisme de porte** : Chaque niveau poss√®de une fonction de porte avec activation GELU
- **Connexions r√©siduelles** : `x = GELU(fx + gx)` o√π `fx` est la transformation normalis√©e et `gx` la fonction de porte

Cette architecture permet d'apprendre des repr√©sentations hi√©rarchiques complexes tout en maintenant la stabilit√© d'entra√Ænement.

### 2. Livre de Codes de M√©ta-√âtats (`MetaStateCodebook`)

Le syst√®me utilise la quantification vectorielle pour d√©couvrir automatiquement les m√©ta-√©tats latents :

- **Embeddings apprenables** : Param√®tres de taille `(codebook_size, latent_dim)`
- **Attribution par distance** : Utilise la distance euclidienne pour assigner les codes
- **Discr√©tisation** : Transforme les repr√©sentations continues en indices discrets

Cette approche permet de d√©couvrir automatiquement les √©tats cach√©s comme "verrouill√©" et "d√©verrouill√©" sans supervision.

### 3. D√©codeur Causal (`CausalDecoder`)

Le d√©codeur pr√©dit les relations causales bas√©es sur les m√©ta-√©tats identifi√©s :

- **Architecture profonde** : Couches lin√©aires avec activations GELU
- **Sortie probabiliste** : Fonction sigmo√Øde pour les probabilit√©s causales
- **Matrice causale** : Sortie de forme `(num_vars, num_vars)` repr√©sentant les liens causaux

## Fonctions de Perte et Objectifs d'Apprentissage

### 1. Perte Causale Principale

```python
def causal_loss(mask_logits, delta_matrix, lambda_1=1.0, lambda_2=0.1):
    # Encourage la pr√©diction correcte des liens causaux
    pos_loss = -Œª‚ÇÅ * log(P(causal)) pour les vrais liens
    neg_loss = -Œª‚ÇÇ * log(1-P(causal)) pour les faux liens
```

### 2. R√©compense de Curiosit√©

L'entropie de Shannon guide l'exploration :
```python
entropy = -Œ£ P(causal) * log‚ÇÇ(P(causal))
```

Cette m√©trique encourage l'agent √† explorer les √©tats avec une haute incertitude causale.

### 3. Pertes Additionnelles (Version Am√©lior√©e)

- **Perte d'engagement** : `||z - quantize(z)||¬≤` pour stabiliser la quantification
- **Perte de parcimonie** : `||mask_logits||‚ÇÅ` pour encourager des graphes causaux simples

## Environnement : Le Probl√®me de la Porte

### Description du Domaine

L'environnement simule une porte avec deux variables d'√©tat :
- `Is_Open` : √âtat d'ouverture (0/1)
- `Is_Locked` : √âtat de verrouillage (0/1)

### Actions Disponibles

1. **PUSH_DOOR** : Pousse la porte (efficace seulement si d√©verrouill√©e)
2. **UNLOCK_DOOR** : D√©verrouille la porte
3. **LOCK_DOOR** : Verrouille la porte

### Dynamiques Causales

La relation causale cl√© d√©pend du m√©ta-√©tat :
- **√âtat d√©verrouill√©** : Push ‚Üí Open (lien causal actif)
- **√âtat verrouill√©** : Push ‚Üõ Open (pas de lien causal)

## Strat√©gie d'Exploration Curieuse

### M√©canisme de D√©cision

L'agent utilise une strat√©gie Œµ-greedy avec d√©croissance :
1. **Exploration al√©atoire** : Probabilit√© Œµ d√©croissante
2. **Exploration dirig√©e** : S√©lection de l'action maximisant la curiosit√©
3. **√âvaluation prospective** : `env.peek_action()` pour simuler les r√©sultats

### Processus de R√©flexion

Le syst√®me affiche explicitement son processus de d√©cision :
```
ü§î Agent's Thought Process...
   - Considering action 'PUSH_DOOR'... Predicted curiosity score: 0.8374
   - Considering action 'UNLOCK_DOOR'... Predicted curiosity score: 0.2156
   - Conclusion: 'PUSH_DOOR' is the most informative action to take.
```

## Analyse des R√©sultats

### Convergence d'Apprentissage

L'entra√Ænement montre plusieurs phases :
1. **Phase d'exploration** : Curiosit√© √©lev√©e, pertes instables
2. **Phase de d√©couverte** : Identification des m√©ta-√©tats
3. **Phase de consolidation** : Stabilisation des pr√©dictions causales

### Graphes Causaux Appris

Le syst√®me visualise les graphes causaux d√©couverts :
```
Learned Causal Graph for Meta-State 0:
      Causes -> | Is_Open | Is_Locked
--------------------------------------
Var 'Is_Open'   |  0.89   |  0.12
Var 'Is_Locked' |  0.15   |  0.91

Interpretation: In this state, 'Push' likely causes 'Open'. (Door appears UNLOCKED)
```

## Innovations Techniques

### 1. Architecture Fractale

- **R√©currence multi-√©chelle** : Traitement √† diff√©rents niveaux d'abstraction
- **Stabilit√© num√©rique** : Normalisation et m√©canismes de porte
- **Expressivit√©** : Capacit√© √† capturer des d√©pendances complexes

### 2. Apprentissage M√©ta-Causal

- **D√©couverte automatique** : Pas de supervision sur les m√©ta-√©tats
- **G√©n√©ralisation** : Applicable √† diff√©rents domaines
- **Interpr√©tabilit√©** : Visualisation des relations apprises

### 3. Curiosit√© Informative

- **Th√©orie de l'information** : Base sur l'entropie de Shannon
- **Exploration efficace** : Focus sur les √©tats incertains
- **Apprentissage actif** : L'agent choisit ses propres exp√©riences

## Limites et Am√©liorations Possibles

### Limitations Actuelles

1. **Scalabilit√©** : Test√© uniquement sur un probl√®me simple (2 variables)
2. **Complexit√© computationnelle** : Architecture fractale co√ªteuse
3. **Hyperparam√®tres sensibles** : N√©cessite un r√©glage fin des poids des pertes

### Directions d'Am√©lioration

1. **Extension multi-domaines** : Test sur des environnements plus complexes
2. **Apprentissage hi√©rarchique** : D√©couverte de m√©ta-√©tats √† plusieurs niveaux
3. **Transfert de connaissances** : R√©utilisation des graphes causaux appris
4. **Robustesse** : Gestion du bruit et des observations partielles

## Implications Th√©oriques

### Contribution √† l'IA Causale

Ce travail advance plusieurs aspects de l'apprentissage causal :
- **Automatisation** : D√©couverte non-supervis√©e de structures causales
- **Contextualisation** : Adaptation des relations causales aux m√©ta-√©tats
- **Motivation intrins√®que** : Exploration guid√©e par la curiosit√©

### Parall√®les Biologiques

L'architecture refl√®te des m√©canismes cognitifs naturels :
- **Hi√©rarchie corticale** : Traitement multi-niveaux dans le cerveau
- **Attention s√©lective** : Focus sur les informations surprenantes
- **Mod√©lisation causale** : Compr√©hension intuitive des relations cause-effet

## Conclusion

L'encodeur fractal pour l'apprentissage causal curieux repr√©sente une approche prometteuse pour l'intelligence artificielle autonome. En combinant la d√©couverte automatique de m√©ta-√©tats avec l'apprentissage de graphes causaux, le syst√®me d√©montre une capacit√© remarquable √† comprendre et √† naviguer dans des environnements complexes.

Les r√©sultats exp√©rimentaux sur le probl√®me de la porte valident l'efficacit√© de l'approche, tout en ouvrant des perspectives passionnantes pour des applications plus larges en robotique, en science des donn√©es et en intelligence artificielle g√©n√©rale.

Cette architecture pourrait constituer un fondement important pour le d√©veloppement d'agents autonomes capables d'apprendre et de raisonner sur la causalit√© dans des environnements r√©els, contribuant ainsi √† l'objectif √† long terme d'une intelligence artificielle v√©ritablement g√©n√©rale et adaptative.